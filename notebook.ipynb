{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from networks - Stonks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the libraries we will use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import extended_networkx as ex\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph and compute market capitalization\n",
    "\n",
    "First of all let's start by loading the graph file, then we compute what we called \"market capitalization\" which is how much an node has been bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph contains 25396 nodes and 396114 edges.\n",
      "There are 6 connected components.\n",
      "Sizes: [25189, 125, 38, 18, 13, 13]\n"
     ]
    }
   ],
   "source": [
    "# Load Graph\n",
    "G = nx.read_gml(\"out_graph.gml\")\n",
    "G_undirected = G.to_undirected() # Needed to compute the number of connected components\n",
    "\n",
    "print(f\"The graph contains {len(G.nodes())} nodes and {len(G.edges())} edges.\")\n",
    "print(f\"There are {nx.number_connected_components(G_undirected)} connected components.\")\n",
    "print(f\"Sizes: {[len(c) for c in sorted(nx.connected_components(G_undirected), key=len, reverse=True)]}\")\n",
    "\n",
    "#print(f\"The diameter of the graph is {nx.diameter(G)}.\")\n",
    "\n",
    "\n",
    "def compute_capitalization(G: nx.Graph):\n",
    "    \"\"\"\n",
    "    Adds the 'capitalization' attribute to every node, which is the sum of the incoming edges weights.\n",
    "    \"\"\"\n",
    "    for node in G.nodes():\n",
    "        capitalization = 0\n",
    "        for edge in G.in_edges(node):\n",
    "            capitalization += G.get_edge_data(*edge)[\"weight\"]\n",
    "        G.nodes[node][\"capitalization\"] = capitalization\n",
    "\n",
    "compute_capitalization(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the top 20 capitalization nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 nodes with highest capitalization: ['CPIN', 'AAPL', 'MSFT', 'AMZN', 'ADRO', 'GOOGL', 'FB', 'GOOG', 'TSLA', 'NVDA', 'JPM', 'UNVR', 'JNJ', 'V', 'UNH', 'HD', 'PG', 'BAC', 'MA', 'PYPL']\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "print(f\"Top {k} nodes with highest capitalization: {ex.max_k_nodes(G, k, 'capitalization')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node-level features\n",
    "\n",
    "### Betweenness centrality\n",
    "\n",
    "We try to compute betweenness centralities of the nodes. The graph is too big to compute the exact betweenness centrality of each node, so we only use a small percentage of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('VSS', 0.00039015861850308207), ('IEUR', 0.00020972093767834395), ('VXF', 0.00020234186764892073), ('IEFA', 0.00011503581803763977), ('VWO', 0.0001092879108568259), ('GEM', 0.0001083558178004777), ('CRBN', 9.429674753389242e-05), ('HNDL', 8.039302611003185e-05), ('RALS', 7.534418872147912e-05), ('FM', 6.322697898895257e-05), ('ITOT', 5.771209507222576e-05), ('SMCP', 5.476046706045647e-05), ('CEY', 4.6915350502859166e-05), ('GDXJ', 4.1400466586132344e-05), ('FNX', 3.495348961305732e-05), ('IWO', 3.425441982079618e-05), ('VIS', 3.417674539943383e-05), ('HART', 3.4099070978071477e-05), ('VGT', 3.1147442966302194e-05), ('IWN', 2.8506512639982304e-05)]\n"
     ]
    }
   ],
   "source": [
    "b_centralities = ex.betweenness_centrality_percent(G, percentage=0.02)\n",
    "print(sorted(b_centralities.items(), key=lambda t: t[1], reverse=True)[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering coefficients\n",
    "\n",
    "The computation for the exact clustering coefficient is doable ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 nodes by clustering coefficient\n",
      "[('RWVG', 2.220278602733271e-05), ('UNA', 1.9880340687835784e-05), ('SSI', 1.5219529225139582e-05), ('HPG', 1.2501223578956097e-05), ('PDR', 1.2427193087025836e-05), ('CRHl', 1.2137344349100606e-05), ('VIC', 1.1967758246053812e-05), ('KRZ', 1.1909451311225256e-05), ('BCM', 1.1672895376409549e-05), ('RWGV', 1.1043518322844037e-05), ('VHM', 1.0180368464746611e-05), ('VCI', 8.455830606685144e-06), ('NVL', 8.304115970363736e-06), ('HSG', 8.276992510958094e-06), ('GEX', 7.798399073501852e-06), ('EXK', 7.639429907146357e-06), ('VCB', 7.093919710666592e-06), ('NOVO', 6.784985924541269e-06), ('JETl', 6.676593093953429e-06), ('DGC', 6.654628072496844e-06)]\n",
      "Global clustering coefficient: 9.24110477412097e-05\n"
     ]
    }
   ],
   "source": [
    "nodes_clustering_coeff = nx.clustering(G, weight=\"weight\")\n",
    "# Print top k nodes with highest clustering coefficient\n",
    "print(f\"Top {k} nodes by clustering coefficient\") \n",
    "print(sorted(nodes_clustering_coeff.items(), key=lambda t: t[1], reverse=True)[:k])\n",
    "print(f\"Global clustering coefficient: {nx.transitivity(G)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closeness Centrality\n",
    "\n",
    "Since the graph has more than one connected component, in order to compute closeness centrality for all the nodes, we use an algotithm found on the internet which basically computes the shortest paths using the Floyd â€” Warshall Method and uses the shortest path Matrix to calculate the closeness metric for each node. It returnes for each node the quantity $$c(v) = \\frac{(n_v - 1)^2}{(n - 1) \\sum_{u \\in C_v}d(v, u)}$$ \n",
    "While `ex.closeness_centrality_matrix(G)` takes approximately two minutes to be executed, `nx.closeness_centrality(G, wf_improved=True)` takes more than 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 109.78453803062439 seconds\n",
      "[(19446, 0.3925908437613524), (19466, 0.12381470128322727), (19464, 0.12100044778931104), (19546, 0.10921951387606549), (19544, 0.030386053711497295), (19543, 0.021701217297901722), (19545, 0.019524774708658828), (19468, 0.013310213897087787), (19482, 0.010609925288797593), (19441, 0.005769172407180744), (19485, 0.005458232143275128), (19442, 0.005106896958476084), (19459, 0.0037305443794605955), (19536, 0.0035766344016292697), (19457, 0.0033738071048927264), (19354, 0.002014289322675759), (19490, 0.002002185430902044), (19357, 0.0014866655346868582), (19488, 0.0013572976578982699), (19483, 0.0013049781760334797)]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "c_centralities = ex.closeness_centrality_matrix(G)\n",
    "print(f'Time: {time.time() - start} seconds')\n",
    "print(sorted(c_centralities.items(), key=lambda t: t[1], reverse=True)[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an approximation we compute the closeness centrality of the nodes in a small random connected subgraph.\n",
    "We devised our own algorithm to draw a connected sample of `k` nodes from the graph `G`: `connected_random_subgraph(G, n)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 components with more than 8000 nodes.\n",
      "[('AMZN', 0.015164315921655812), ('AAPL', 0.015055554260666765), ('TXN', 0.012727835323306815), ('KEY', 0.012558696533899318), ('QCOM', 0.012404675584448055), ('JNJ', 0.012335738858549028), ('CMCSA', 0.012311790772407702), ('LH', 0.012282493255582182), ('IBM', 0.012177850733757179), ('PPL', 0.012177850733757179), ('CSCO', 0.01217053540143222), ('GS', 0.011922020053831231), ('IP', 0.011776788554265486), ('TGT', 0.011670576469117464), ('PRU', 0.011588373834085583), ('MMM', 0.011534371904014885), ('PAYX', 0.011361560055146753), ('PG', 0.01135894675006419), ('TSN', 0.011254154022000005), ('DGX', 0.01122218199352841)]\n"
     ]
    }
   ],
   "source": [
    "sub_G = ex.connected_random_subgraph(G, 8000)\n",
    "c_centralities = nx.closeness_centrality(sub_G)\n",
    "print(sorted(c_centralities.items(), key=lambda t: t[1], reverse=True)[:k])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5204a74533213595f4cb17824e0251b8e042fe549e56b4e3fea578127d6ef366"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
